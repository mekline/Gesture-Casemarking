WOall <- unlist(strsplit(as.character(WOques), "[,]"))
tog <- paste(WOall, sep = '', collapse = '')
lasttog <- str_match(tog, '[\\(\\)]*[SOV]?[\\(\\)]*[SOV]?[\\(\\)]*[SOV][\\(\\)]*$')
MigLast3 <- append(MigLast3, lasttog)
}
gestable$Mig.Last3 = MigLast3
gestable[is.na(gestable$Mig.Last3),]$Mig.Last3 <- ''
gestable$Mig.Last3
#Add column that compares old and new coding of only the last 3 gestures
gestable$Last3.Compare <- (as.character(gestable$Eun.Last3) == as.character(gestable$Mig.Last3))
lst3compavg <- mean(gestable$Last3.Compare)
print(paste0('Last3 Direct Agreement: ', lst3compavg))
####
# Again, by-hand calculation of Cohen's Kappa
####
#Calculate Cohen's Kappa for Last3 Compare
first3lev <- levels(as.factor(gestable$Eun.Last3))
second3lev <- levels(as.factor(gestable$Mig.Last3))
all3lev <- levels(factor(c(first3lev, second3lev)))
litfirst3prob <- rep(0, length(all3lev))
litsecond3prob <- rep(0, length(all3lev))
for (i in gestable$Eun.Last3) {
for (j in 1:(length(all3lev))) {
if (i == all3lev[j]) {
litfirst3prob[j] <- litfirst3prob[j]+1
}
}
}
for (k in gestable$Mig.Last3) {
for (l in 1:(length(all3lev))) {
if (k == all3lev[l]) {
litsecond3prob[l] <- litsecond3prob[l]+1
}
}
}
#Come up with random probability percentages for each level
percent3_1 = litfirst3prob/length(gestable$Eun.Last3)
percent3_2 = litsecond3prob/length(gestable$Eun.Last3)
lst3percents = percent3_1*percent3_2
lst3randprob = 0
for (w in lst3percents) {lst3randprob = lst3randprob+w}
lst3kappa = (lst3compavg-lst3randprob)/(1-lst3randprob)
print(paste0('Last3 Kappa (Manual): ', lst3kappa))
####
# End manual kappa
####
####
# OK, now let's try kappa2 from the irr package, does it match?
####
kappa2(gestable[,c('Eun.Last3','Mig.Last3')]) #Not sure about the weight paradigm! but this matches Miguel
#Produce table that spits out disagreement on WORD ORDER.
noagreetable2 <- gestable[gestable$Last3.Compare == 0,]
noagreetable2 <- noagreetable2[,c("Subject", "GestureCondition", "Trial.Number", "Clipped.Movie.File", "Event", "Eun.Last3", "Mig.Last3", "Initial.Coder", "Blind.Coder")]
write.csv(noagreetable2, file = paste0(directory, "/Last3NoAgree.csv"))
#Produce table that spits out disagreement on SPATIAL.
noagreetable4 <- gestable[gestable$SpaCue.Agree == 0,]
noagreetable4 <- noagreetable4[,c("Subject", "GestureCondition", "Trial.Number", "Clipped.Movie.File", "Event", "Spatial.Cue", "Spatial.Cue.Recode", "Initial.Coder", "Blind.Coder")]
write.csv(noagreetable4, file = paste0(directory, "/SpatialNoAgree.csv"))
########
# AT THIS POINT, a third coder worked with Miguel to tiebreak/resolve by discussion any video that had been coded
# differently by the two coders. For Word Order, their final judgement, and the nature of the disagreement, are recorded in 2
# new columns in the file Last3NoAgree_Reconciliation.csv, loaded back in below.
#
# For Spatial, their final judgment is recorder in SpatialNoAgree_Reconciliation.csv.  It turned out that agreement was
# initially very low, so we reworked the spatial definitions, and Reconciliation was done by adhering to this new
# standard in discussion. Finally, a coder blind to all hypotheses in the experiment coded 10% of the spatial
# info task following these new instructions.
########
#Load the files back in
wordOrderNoAgreeTable <- read.csv(paste0(directory, "/Last3NoAgreeReconciliation.csv"), header = TRUE)
spatialNoAgreeTable <- read.csv(paste0(directory, "/SpatialNoAgreeReconciliation.csv"), header = TRUE)
#Drop columns that are just duplicated in gestable/we don't need.
wordOrderNoAgreeTable <- wordOrderNoAgreeTable[,c('Subject','GestureCondition','Trial.Number', 'Final.Decision', 'Final.Clean', 'Multiple.V', 'Discussed.With', 'Disagree.Reason')]
spatialNoAgreeTable$Spatial.Final.Decision <- spatialNoAgreeTable$Final.Decision
spatialNoAgreeTable$Spatial.Discussed.With <- spatialNoAgreeTable$Discussed.With
spatialNoAgreeTable <- spatialNoAgreeTable[,c('Subject','GestureCondition','Trial.Number','Spatial.Final.Decision','Spatial.Discussed.With')]
######
#Merge those lines back on!
#For WordOrder, We need to make a 'final clean' column that takes 1) Eun Last3 coding where there
#is no disagreement, and 2) FinalClean where there was disagreement. Also mark disagreement type as either what
#it was, or as noDisagreement.
#For Spatial, FinalDecision will be the final decision from Miguel/Mitchell discussion, OR the original if there was
#no disagreement. Disagreement type isn't marked, there's just spatial or no...
#
# Also keep a 'final long' column that lists people's whole gesture sequence, so we can compare those...
alldata <- merge(gestable, wordOrderNoAgreeTable, by=c('Subject','GestureCondition','Trial.Number'), all=TRUE)
alldata <- merge(alldata, spatialNoAgreeTable, by=c('Subject','GestureCondition','Trial.Number'), all=TRUE)
alldata$Disagree.Reason <- as.character(alldata$Disagree.Reason)
alldata[is.na(alldata$Final.Clean),]$Disagree.Reason <- "NoDisagreement"
alldata$Final.Clean <- as.character(alldata$Final.Clean)
alldata[is.na(alldata$Final.Clean),]$Final.Clean <- alldata[is.na(alldata$Final.Clean),]$Eun.Last3
alldata[is.na(alldata$Spatial.Final.Decision),]$Spatial.Final.Decision <- alldata[is.na(alldata$Spatial.Final.Decision),]$Spatial.Cue
alldata$Final.Long <- as.character(alldata$Final.Decision)
alldata[is.na(alldata$Final.Long),]$Final.Long <- alldata[is.na(alldata$Final.Long),]$Word.Order #Miguel/Eunice's original original coding!
#######
# Final agreement calculations to report!
#Classify all items as VerbMedial, VerbLateral, or Unclassified
#This also decides individual items to exclude (for not consisting of exactly one S,V,O, or for having
# parenthesis orders that make verb medial/final judgment impossible.
alldata$WordOrder.Classified <- "Unclassified"
alldata[alldata$Final.Clean == "SOV",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "OSV",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "VSO",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "VOS",]$WordOrder.Classified <- "VerbLateral"
#Parenthesis cases!
alldata[alldata$Final.Clean == "V(OS)",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "V(SO)",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "(SO)V",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "(OS)V",]$WordOrder.Classified <- "VerbLateral"
alldata[alldata$Final.Clean == "SVO",]$WordOrder.Classified <- "VerbMedial"
alldata[alldata$Final.Clean == "OVS",]$WordOrder.Classified <- "VerbMedial"
#And find out the final kappa numbers we need: Agreement by Medial/Lateral/Undefined, and Spatial agreement ala Katy
#Have to restate Eun.Last3 and Mig.Last3 in the same way as final decisions for this....
alldata[is.na(alldata$Eun.Last3),]$Eun.Last3 <- "NoCode"
alldata$Eun.Classified <- "Unclassified"
alldata[alldata$Eun.Last3 == "SOV",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "OSV",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "VSO",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "VOS",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "V(OS)",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "V(SO)",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "(SO)V",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "(OS)V",]$Eun.Classified <- "VerbLateral"
alldata[alldata$Eun.Last3 == "SVO",]$Eun.Classified <- "VerbMedial"
alldata[alldata$Eun.Last3 == "OVS",]$Eun.Classified <- "VerbMedial"
alldata[is.na(alldata$Mig.Last3),]$Mig.Last3 <- "NoCode"
alldata$Mig.Classified <- "Unclassified"
alldata[alldata$Mig.Last3 == "SOV",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "OSV",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "VSO",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "VOS",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "V(OS)",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "V(SO)",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "(SO)V",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "(OS)V",]$Mig.Classified <- "VerbLateral"
alldata[alldata$Mig.Last3 == "SVO",]$Mig.Classified <- "VerbMedial"
alldata[alldata$Mig.Last3 == "OVS",]$Mig.Classified <- "VerbMedial"
kappa2(alldata[,c('Mig.Classified','Eun.Classified')]) #Not sure about the weight paradigm! but this matches Miguel
alldata$Classified.WO.Compare <- alldata$Mig.Classified == alldata$Eun.Classified
mean(alldata$Classified.WO.Compare)
#And spatial-Katy agreement
katydata <- alldata[!is.na(alldata$Spatial.Cue.Katy),]
kappa2(katydata[,c('Spatial.Cue.Katy','Spatial.Final.Decision')])
katydata$Classified.Spatial.Compare <- katydata$Spatial.Cue.Katy == katydata$Spatial.Final.Decision
mean(katydata$Classified.Spatial.Compare)
######
# Column cleanup and renaming
#Now drop all the preliminary codings & 'mush' columns, leaving us with just Final.WordOrder.Clean and Final.Spatial.Clean
#And give them slightly more transparent names...
alldata <- alldata[,c("Subject","GestureCondition","Trial.Number","Object.Type","Event","Used.ASL","X.Embodied..in.some.way","Final.Long", "Final.Clean","WordOrder.Classified","Spatial.Final.Decision","Clipped.Movie.File")]
names(alldata) <- c("Subject", "GestureCondition","Trial.Number", "Object.Type", "Sentence", "Used.ASL", "Embodiment", "Final.Full.WordOrder", "WordOrder","WordOrder.Classified","SpatialCue","Clipped.Movie.File" )
#Make some columns easier for humans to read...
alldata$SpatialCue <- as.character(alldata$SpatialCue)
alldata[is.na(alldata$SpatialCue),]$SpatialCue <- "NA"
alldata[alldata$SpatialCue == 1,]$SpatialCue <- "Spatial.Present"
alldata[alldata$SpatialCue == 0,]$SpatialCue <- "Spatial.Absent"
######
# Final item inclusion/checking
# Find out: How many items did each person complete?
#Make sure the dropped people really got dropped, they snuck back in during item comparisons...
subtable <- subtable[c("Participant","To.include")]
names(subtable) <- c("Subject","ToInclude")
alldata <- merge(alldata, subtable, by=c("Subject"))
alldata <- alldata[alldata$ToInclude == 1,]
numSigns <- aggregate(alldata$WordOrder, by=list(alldata$Subject),length)
#Yay! Everyone did all the trials!
#################################################################
#################################################################
#################################################################
##DESCRIPTIVES AND STATISTICS
#################################################################
#################################################################
#################################################################
#################################################################
## Basic descriptions (we report proportions rather than raw # of responses in the paper, see below. )
#Report S counts
length(unique(alldata$Subject))
#Counts of SOV versus SVO instances in Free and Hand conditions
table(alldata$WordOrder.Classified, alldata$Object.Type, alldata$GestureCondition)
#Counts of when spatial cues actually produced?
table(alldata$SpatialCue, alldata$WordOrder.Classified, alldata$Object.Type)
#Spatial cue counts in Gesture task 1...
#What about early casemarkers?
noinstructiondata <- alldata[alldata$GestureCondition == "Free",]
table(noinstructiondata$SpatialCue, noinstructiondata$WordOrder.Classified, noinstructiondata$Object.Type)
#....and 2
instructiondata <- alldata[alldata$GestureCondition == "Case",]
table(instructiondata$SpatialCue, instructiondata$WordOrder.Classified, instructiondata$Object.Type)
#################################################################
## Checking item classification scheme (classification to verb Medial/Nonmedial)
#How many items are just an S, O, and V?
#Does full letter seq not equal final 3?
#Was item Unclassified?
#Parentheses?
#Mark all those in case anyone is worried about our data coding....
alldata$SuperGoodResponse <- "Yes"
alldata[alldata$Final.Full.WordOrder != alldata$WordOrder,]$SuperGoodResponse <- "No"
alldata[alldata$WordOrder.Classified == "Unclassified",]$SuperGoodResponse <- "No"
alldata[alldata$WordOrder == "(SO)V",]$SuperGoodResponse <- "No"
#Examine items that didn't fit the classifcation scheme well
foo <- alldata[alldata$Final.Full.WordOrder != alldata$WordOrder & alldata$WordOrder.Classified != "Unclassified",]$Final.Full.WordOrder
goo <- as.data.frame(foo)
goo$len <- unlist(lapply(foo, nchar))
goo <- goo[goo$len > 3,]
goo[order(goo$foo),]
#(And do some manual checking about items that might have been misclassified)
#OK: For items longer than length 3 that DID get classified, here are places we might have mistakes:
# OVOSV (1) - maybe not SOV
# SOVSVO 2 - maybe not SVO
#################################################################
#'Embodiment' (presence of body-based sign) - added coding and recalculating orders in the way relevant to Hall's theory (deal w edge cases)
# We want to check if Embodiment (in the second task)
# made a difference for SOV use (ie maybe we did an embodiment manipulation
# alongside...).  For this, read in the new Embodiment coding that Miguel
# did ~ 10/22/14
embodiment_data <- read.csv(paste0(directory, "/EmbodimentRecode.csv"), header = TRUE)
#drop some duplicate columns we dont' need...
embodiment_data <- embodiment_data[,c("Clipped.Movie.File","Trial.Number", "Agent.Embod","Verb.Embod","Patient.Embod")]
alldata <- merge(alldata, embodiment_data, by=c("Clipped.Movie.File","Trial.Number"),all.X=TRUE, all.y=FALSE)
#Did Embodiment change across the 2 conditions? Check Agent Verb Patient
table(alldata$Agent.Embod, alldata$Object.Type, alldata$GestureCondition)
table(alldata$Verb.Embod, alldata$Object.Type, alldata$GestureCondition)
table(alldata$Patient.Embod, alldata$Object.Type, alldata$GestureCondition)
#Embodicment hyp is centrally about avoiding role
#conflict between V and O.  This means a) recode WordOrder for *presence of that string*, and b)
# the Embody metric we care about is intersect(V,O)
#drop ?s!
alldata <- alldata[alldata$Agent.Embod != "?",]
alldata <- alldata[alldata$Verb.Embod != "?",]
alldata <- alldata[alldata$Patient.Embod != "?",]
alldata$Agent.Embod <- as.numeric(as.character(alldata$Agent.Embod))
alldata$Verb.Embod <- as.numeric(as.character(alldata$Verb.Embod))
alldata$Patient.Embod <- as.numeric(as.character(alldata$Patient.Embod))
alldata$PV.Embod <- (alldata$Verb.Embod == 1) & (alldata$Patient.Embod == 1)
#Add New WordOrder classifications! The distinction is whether s is the last
#entity before the v. (this is what the constraint wants)
alldata[is.na(alldata$WordOrder),]$WordOrder <- "Unclassified"
alldata$WordOrder.Embod.Classified <- "Unclassified"
alldata[alldata$WordOrder == "SOV",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "OSV",]$WordOrder.Embod.Classified <- "Adjacent"
alldata[alldata$WordOrder == "VSO",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "VOS",]$WordOrder.Embod.Classified <- "NonAdjacent"
#Parenthesis cases
alldata[alldata$WordOrder == "V(OS)",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "V(SO)",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "(SO)V",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "(OS)V",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "SVO",]$WordOrder.Embod.Classified <- "Adjacent"
alldata[alldata$WordOrder == "OVS",]$WordOrder.Embod.Classified <- "NonAdjacent"
#################################################################
## REPORTED PROPORTION SCORES AND CORRESPONDING MODELS
# Note - "ChoseLateral" = Verb Non-medial, ie the category that's mostly SOV.
#Drop Unclassified items
alldata <- alldata[!(alldata$WordOrder.Classified == "Unclassified"),]
alldata <- alldata[!(alldata$SpatialCue == "?"),]
alldata[is.na(alldata$WordOrder.Classified),]$WordOrder.Classified <-"Unclassified"
#Forcing everything to be a factor, just in case
alldata$WordOrder.Classified <- as.factor(alldata$WordOrder.Classified)
alldata$Object.Type <- as.factor(alldata$Object.Type)
alldata$SpatialCue <- as.factor(alldata$SpatialCue)
alldata$GestureCondition <- as.factor(alldata$GestureCondition)
freedata <- alldata[alldata$GestureCondition == "Free",]
handdata <- alldata[alldata$GestureCondition == "Case",]
freedata$WordOrder.Classified <- as.factor(freedata$WordOrder.Classified)
handdata$WordOrder.Classified <- as.factor(handdata$WordOrder.Classified)
freedata$Object.Type <- as.factor(freedata$Object.Type)
handdata$Object.Type <- as.factor(handdata$Object.Type)
#################
#WORD ORDER
#Make scores for each participant
alldata$ChoseLateral <- 0
alldata[alldata$WordOrder.Classified == "VerbLateral",]$ChoseLateral <- 1
ParticipantScores <- aggregate(alldata$ChoseLateral, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(ParticipantScores) <- c("Subject", "Object.Type", "GestureCondition", "ChoseLateral")
#################
#WORD ORDER
#Make scores for each participant
alldata$ChoseLateral <- 0
alldata[alldata$WordOrder.Classified == "VerbLateral",]$ChoseLateral <- 1
ParticipantScores <- aggregate(alldata$ChoseLateral, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(ParticipantScores) <- c("Subject", "Object.Type", "GestureCondition", "ChoseLateral")
#### GRAPHS AND STATS!!!! ######
# 3/20/15 Reordering stats to match paper order, calculating confints, and redoing model comparisons (rather than reporting p vals from the wrong variable coding)
###
# GRAPH #1 - ChoseLateral by Object Type and Gesture Condition
###
#Table for scores
with(ParticipantScores, tapply(ChoseLateral, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
#CONF INTERVALS
#Bootstrapped confidence intervals around the means of the 4 conditions!
PersonFree.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Person" & ParticipantScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Person" & ParticipantScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
ObjectFree.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Object" & ParticipantScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(ObjectFree.boot.mean$thetastar, c(0.025, 0.975))
ObjectHand.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Object" & ParticipantScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(ObjectHand.boot.mean$thetastar, c(0.025, 0.975))
#MODELS for graph 1
#In each experiment- were people more likely to use SVO with Animate?
#free_model <- lmer(WordOrder.Classified ~ Object.Type  + (Object.Type|Subject), data=freedata, family="binomial")
#Failed to converge! Remove random slope
free_model_noslope <- lmer(WordOrder.Classified ~ Object.Type  + (1|Subject), data=freedata, family="binomial")
summary(free_model_noslope)
foo <- lmer(WordOrder.Classified ~  (1|Subject), data=freedata, family="binomial")
anova(free_model_noslope,foo)
names(freedata)
freedata$Trial.Number
freedata[,c("Trial.Number","Sentence")]
free_model <- lmer(WordOrder.Classified ~ Object.Type  + (Object.Type|Subject) + (1|Sentence), data=freedata, family="binomial")
free_model_noslope <- lmer(WordOrder.Classified ~ Object.Type  + (1|Subject), data=freedata, family="binomial")
summary(free_model_noslope)
free_model <- lmer(WordOrder.Classified ~ Object.Type  + (Object.Type|Subject) + (1|Sentence), data=freedata, family="binomial")
summary(free_model)
free_model <- lmer(WordOrder.Classified ~ Object.Type  + (Object.Type|Subject) + (1|Sentence), data=freedata, family="binomial")
summary(free_model)
hand_model <- lmer(WordOrder.Classified ~ Object.Type  + (Object.Type|Subject) + (1|Sentence), data=handdata, family="binomial")
summary(hand_model)
anova(free_model,free_nofix)
free_nofix <- lmer(WordOrder.Classified ~ (Object.Type|Subject) + (1|Sentence), data=freedata, family="binomial")
anova(free_model,free_nofix)
hand_model <- lmer(WordOrder.Classified ~ Object.Type  + (Object.Type|Subject) + (1|Sentence), data=handdata, family="binomial")
hand_nofix <- lmer(WordOrder.Classified ~  (Object.Type|Subject) + (1|Sentence), data=handdata, family="binomial")
anova(hand_model,hand_nofix)
word_order_model <- lmer(WordOrder.Classified ~ Object.Type*GestureCondition  + (Object.Type*GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
word_order_model <- lmer(WordOrder.Classified ~ Object.Type*GestureCondition  + (Object.Type+GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
word_order_model <- lmer(WordOrder.Classified ~ Object.Type*GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
word_order_model2 <- lmer(WordOrder.Classified ~ Object.Type+GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(word_order_model, word_order_model2)
word_order_model <- lmer(WordOrder.Classified ~ GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(word_order_model2, word_order_model3)
word_order_model3 <- lmer(WordOrder.Classified ~ GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
word_order_model <- lmer(WordOrder.Classified ~ Object.Type*GestureCondition  + (Object.Type|Subject) + (1|Sentence), data=alldata, family="binomial")
word_order_model <- lmer(WordOrder.Classified ~ Object.Type*GestureCondition  + (1|Subject) + (1|Sentence), data=alldata, family="binomial")
word_order_model2 <- lmer(WordOrder.Classified ~ Object.Type+GestureCondition  + (1|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(word_order_model, word_order_model2)
word_order_model3 <- lmer(WordOrder.Classified ~ GestureCondition  + (1|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(word_order_model2, word_order_model3)
word_order_model4 <- lmer(WordOrder.Classified ~ Object.Type  + (1|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(word_order_model2, word_order_model4)
names(AnimacySpatialScores)
#################
#CASEMARKING
alldata$Casemarked <- 0
alldata[is.na(alldata$SpatialCue),]$SpatialCue <- "Spatial.Absent"
alldata[alldata$SpatialCue == "Spatial.Present",]$Casemarked <- 1
###
# GRAPH 3 (FIGURE 5) - Spatial Cue by Animacy and Experiment
###
#Did they casemark differently depending on animacy?
AnimacySpatialScores <- aggregate(alldata$Casemarked, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(AnimacySpatialScores) <- c("Subject", "Object.Type", "GestureCondition", "Casemarked")
with(AnimacySpatialScores, tapply(Casemarked, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
PersonFree.boot.mean = bootstrap(AnimacyScores[AnimacyScores$Object.Type=="Person" & AnimacyScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(AnimacyScores[AnimacyScores$Object.Type=="Person" & AnimacyScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
ObjectFree.boot.mean = bootstrap(AnimacyScores[AnimacyScores$Object.Type=="Object" & AnimacyScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(ObjectFree.boot.mean$thetastar, c(0.025, 0.975))
ObjectHand.boot.mean = bootstrap(AnimacyScores[AnimacyScores$Object.Type=="Object" & AnimacyScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(ObjectHand.boot.mean$thetastar, c(0.025, 0.975))
PersonFree.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Person" & AnimacySpatialScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Person" & AnimacySpatialScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
ObjectFree.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Object" & AnimacySpatialScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(ObjectFree.boot.mean$thetastar, c(0.025, 0.975))
ObjectHand.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Object" & AnimacySpatialScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(ObjectHand.boot.mean$thetastar, c(0.025, 0.975))
animacy_model <- lmer(Casemarked ~ Object.Type*GestureCondition  + (Object.Type*GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
animacy_model <- lmer(Casemarked ~ Object.Type*GestureCondition  + (Object.Type+GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
animacy_model <- lmer(Casemarked ~ Object.Type*GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
animacy_model2 <- lmer(Casemarked ~ Object.Type+GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(animacy_model, animacy_model2)
animacy_model3 <- lmer(Casemarked ~ Object.Type  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(animacy_model2, animacy_model3)
animacy_model4 <- lmer(Casemarked ~ GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
anova(animacy_model2, animacy_model4)
EmbodPVScores <- aggregate(alldata$PV.Embod, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(EmbodPVScores) <- c("Subject", "Object.Type", "GestureCondition", "PV.Embod")
with(EmbodPVScores, tapply(PV.Embod, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
embod_model <- lmer(PV.Embod ~ GestureCondition*Object.Type + (GestureCondition*Object.Type|Subject) + (1|Sentence), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ GestureCondition*Object.Type, data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ GestureCondition*Object.Type + (1|Sentence), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition  + (Object.Type*GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition  + (Object.Type+GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition  + (1|Subject) + (1|Sentence), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition  + (1|Subject), data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition, data=alldata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition+1, data=alldata, family="binomial")
alldata$PV.Embod
PersonFree.boot.mean = bootstrap(EmbodPVScores[EmbodPVScores$Object.Type=="Person" & EmbodPVScores$GestureCondition=="Free",]$PV.Embod, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(EmbodPVScores[EmbodPVScores$Object.Type=="Person" & EmbodPVScores$GestureCondition=="Case",]$PV.Embod, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
animdata <- alldata[alldata$Object.Type = "Person",]
animdata <- alldata[alldata$Object.Type == "Person",]
animdata
embod_model <- lmer(PV.Embod ~ ~ Object.Type*GestureCondition  + (Object.Type*GestureCondition|Subject) + (1|Sentence), data=animdata, family="binomial")
embod_model <- lmer(PV.Embod ~ Object.Type*GestureCondition  + (Object.Type*GestureCondition|Subject) + (1|Sentence), data=animdata, family="binomial")
embod_model <- lmer(PV.Embod ~ GestureCondition  + (GestureCondition|Subject) + (1|Sentence), data=animdata, family="binomial")
embod_model_nofix <- lmer(PV.Embod ~ 1  + (GestureCondition|Subject) + (1|Sentence), data=animdata, family="binomial")
anova(embod_model, embod_model_nofix)
peopledata <- alldata[alldata$Object.Type == 'Person',]
PeopleSpatialScores <- aggregate(peopledata$ChoseLateral, by=list(peopledata$Subject, peopledata$Casemarked, peopledata$GestureCondition), mean.na.rm)
names(PeopleSpatialScores) <- c("Subject", "Casemarked", "GestureCondition", "ChoseLateral")
with(PeopleSpatialScores, tapply(ChoseLateral, list(Casemarked, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
#CONF INTERVALS
#MODELS
peopledata_free <- peopledata[peopledata$GestureCondition == "Free",]
peopledata_hand <- peopledata[peopledata$GestureCondition == "Case",]
#Check spatial pattern within JUST people trials!
spatial_model_people_free <- lmer(ChoseLateral ~ SpatialCue  + (SpatialCue|Subject) + (1|Sentence), data=peopledata_free, family="binomial")
spatial_nofix <- lmer(ChoseLateral ~ 1  + (SpatialCue|Subject) + (1|Sentence), data=peopledata_free, family="binomial")
anova(spatial_model_people_free, spatial_nofix)
spatial_model_people_hand <- lmer(ChoseLateral ~ SpatialCue  + (SpatialCue|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
spatial_nofix_hand <- lmer(ChoseLateral ~ 1  + (SpatialCue|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
anova(spatial_model_people_hand, spatial_nofix_hand)
spatial_model_people <- lmer(ChoseLateral ~ SpatialCue*GestureCondition  + (SpatialCue*GestureCondition|Subject) + (1|Sentence), data=peopledata, family="binomial")
spatial_model_people <- lmer(ChoseLateral ~ SpatialCue*GestureCondition  + (SpatialCue+GestureCondition|Subject) + (1|Sentence), data=peopledata, family="binomial")
spatial_model_people <- lmer(ChoseLateral ~ SpatialCue*GestureCondition  + (SpatialCue|Subject) + (1|Sentence), data=peopledata, family="binomial")
spatial_model_people <- lmer(ChoseLateral ~ SpatialCue*GestureCondition  + (SpatialCue|Subject) + (1|Sentence), data=peopledata, family="binomial")
spatial_model_people2 <- lmer(ChoseLateral ~ SpatialCue+GestureCondition  + (SpatialCue*GestureCondition|Subject) + (1|Sentence), data=peopledata, family="binomial")
spatial_model_people <- lmer(ChoseLateral ~ SpatialCue*GestureCondition  + (SpatialCue|Subject) + (1|Sentence), data=peopledata, family="binomial")
#remove interaction
spatial_model_people2 <- lmer(ChoseLateral ~ SpatialCue+GestureCondition  + (SpatialCue|Subject) + (1|Sentence), data=peopledata, family="binomial")
anova(spatial_model_people, spatial_model_people2)
PeopleEmbodScores <- aggregate(peopledata$ChoseLateral, by=list(peopledata$Subject, peopledata$PV.Embod, peopledata$GestureCondition), mean.na.rm)
names(PeopleEmbodScores) <- c("Subject", "PVEmbod", "GestureCondition", "ChoseLateral")
#Table for scores too
with(PeopleEmbodScores, tapply(ChoseLateral, list(PVEmbod, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
peopleembod_model_free <- lmer(WordOrder.Classified ~ PV.Embod  + (PV.Embod|Subject) + (1|Sentence), data=peopledata_free, family="binomial")
people_nofix <- lmer(WordOrder.Classified ~ 1  + (PV.Embod|Subject) + (1|Sentence), data=peopledata_free, family="binomial")
anova(peopleembod_model_free,people_nofix)
peopleembod_model_hand <- lmer(WordOrder.Classified ~ PV.Embod  + (PV.Embod|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
peopleembod_nofix2 <- lmer(WordOrder.Classified ~ 1  + (PV.Embod|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
anova(peopleembod_model_hand,people_nofix2)
peopleembod_model_hand <- lmer(WordOrder.Classified ~ PV.Embod  + (1|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
peopleembod_model_hand <- lmer(WordOrder.Classified ~ PV.Embod  + (1|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
peopleembod_nofix2 <- lmer(WordOrder.Classified ~ 1  + (1|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
anova(peopleembod_model_hand,people_nofix2)
peopleembod_model_hand <- lmer(WordOrder.Classified ~ PV.Embod  + (1|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
peopleembod_nofix2 <- lmer(WordOrder.Classified ~ 1  + (1|Subject) + (1|Sentence), data=peopledata_hand, family="binomial")
anova(peopleembod_model_hand,peopleembod_nofix2)
peopleexp_embod_model <- lmer(ChoseLateral ~ GestureCondition*PV.Embod  + (GestureCondition*PV.Embod|Subject) + (1|Sentence), data=peopledata, family="binomial")
peopleexp_embod_model <- lmer(ChoseLateral ~ GestureCondition*PV.Embod  + (GestureCondition+PV.Embod|Subject) + (1|Sentence), data=peopledata, family="binomial")
peopleexp_embod_model <- lmer(ChoseLateral ~ GestureCondition*PV.Embod  + (PV.Embod|Subject) + (1|Sentence), data=peopledata, family="binomial")
peopleexp_embod_model <- lmer(ChoseLateral ~ GestureCondition*PV.Embod  + (PV.Embod|Subject) + (1|Sentence), data=peopledata, family="binomial")
#Compare to dropped interaction
peopleexp_embod_model2 <- lmer(ChoseLateral ~ GestureCondition+PV.Embod  + (PV.Embod|Subject) + (1|Sentence), data=peopledata, family="binomial")
anova(peopleexp_embod_model, peopleexp_embod_model2)
PeopleSpatialScores$Casemarked
CaseFree.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==1 & PeopleSpatialScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(CaseFree.boot.mean$thetastar, c(0.025, 0.975))
with(PeopleSpatialScores, tapply(ChoseLateral, list(Casemarked, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
.61+.97
1.58/2
anova(spatial_model_people, spatial_model_people2)
NoCaseFree.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==0 & PeopleSpatialScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(NoCaseFree.boot.mean$thetastar, c(0.025, 0.975))
CaseFree.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==1 & PeopleSpatialScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(CaseFree.boot.mean$thetastar, c(0.025, 0.975))
NoCaseFree.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==0 & PeopleSpatialScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(NoCaseFree.boot.mean$thetastar, c(0.025, 0.975))
CaseHand.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==1 & PeopleSpatialScores$GestureCondition=="Hand",]$ChoseLateral, 1000, mean)
quantile(CaseHand.boot.mean$thetastar, c(0.025, 0.975))
NoCaseHand.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==0 & PeopleSpatialScores$GestureCondition=="Hand",]$ChoseLateral, 1000, mean)
quantile(NoCaseHand.boot.mean$thetastar, c(0.025, 0.975))
PeopleSpatialScores$GestureCondition
CaseFree.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==1 & PeopleSpatialScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(CaseFree.boot.mean$thetastar, c(0.025, 0.975))
NoCaseFree.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==0 & PeopleSpatialScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(NoCaseFree.boot.mean$thetastar, c(0.025, 0.975))
CaseHand.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==1 & PeopleSpatialScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(CaseHand.boot.mean$thetastar, c(0.025, 0.975))
NoCaseHand.boot.mean = bootstrap(PeopleSpatialScores[PeopleSpatialScores$Casemarked==0 & PeopleSpatialScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(NoCaseHand.boot.mean$thetastar, c(0.025, 0.975))
PeopleEmbodScores$PVEmbod
EmbodFree.boot.mean = bootstrap(PeopleEmbodScores[PeopleEmbodScores$PVEmbod==TRUE & PeopleEmbodScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(EmbodFree.boot.mean$thetastar, c(0.025, 0.975))
with(PeopleEmbodScores, tapply(ChoseLateral, list(PVEmbod, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
EmbodFree.boot.mean = bootstrap(PeopleEmbodScores[PeopleEmbodScores$PVEmbod==TRUE & PeopleEmbodScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(EmbodFree.boot.mean$thetastar, c(0.025, 0.975))
NoEmbodFree.boot.mean = bootstrap(PeopleEmbodScores[PeopleEmbodScores$PVEmbod==FALSE & PeopleEmbodScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(NoEmbodFree.boot.mean$thetastar, c(0.025, 0.975))
EmbodHand.boot.mean = bootstrap(PeopleEmbodScores[PeopleEmbodScores$PVEmbod==TRUE & PeopleEmbodScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(EmbodHand.boot.mean$thetastar, c(0.025, 0.975))
NoEmbodHand.boot.mean = bootstrap(PeopleEmbodScores[PeopleEmbodScores$PVEmbod==FALSE & PeopleEmbodScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(NoEmbodHand.boot.mean$thetastar, c(0.025, 0.975))
peopledata <- alldata[alldata$Object.Type == 'Person',]
table(peopledata$PV.Embod, peopledata$SpatialCue)
embod_case_model <- lmer(PV.Embod ~ SpatialCue  + (SpatialCue|Subject) + (1|Sentence), data=peopledata, family="binomial")
embod_nofix <- lmer(PV.Embod ~ 1  + (SpatialCue|Subject) + (1|Sentence), data=peopledata, family="binomial")
anova(embod_case_model, embod_nofix)
setwd("~/Dropbox/_Projects/Gesture/Gesture-Casemarking Repository/Production-Casemarking/Analysis - Post Blindcoding")
directory = getwd()
gestable = read.csv(paste0(directory, "/quick_embod_kappa_050615.csv"), header = TRUE)
gestable
names(gestable)
gestable$Literal.Compare = (as.character(gestable$OrigEmb) == as.character(gestable$NewEmb))
litcompavg = mean(gestable$Literal.Compare)
print(paste0('Literal Direct Agreement: ', litcompavg))
kappa2(gestable[,c('OrigEmb','NewEmb')])
library(irr)
library(stringr)
library(languageR)
library(lme4)
library(multcomp)
library(binom)
library(bootstrap)
kappa2(gestable[,c('OrigEmb','NewEmb')])
